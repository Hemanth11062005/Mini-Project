{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad4a3e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Hemanth\\Mini Project\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D, BatchNormalization, Dropout, Input, Lambda, Conv2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "import tensorflow.keras.backend as K\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GCNConv, GATConv, global_mean_pool\n",
    "from skimage.segmentation import slic\n",
    "from skimage.util import img_as_float\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Global Variables\n",
    "train_dir = 'Dataset/pest/train'\n",
    "test_dir = 'Dataset/pest/test'\n",
    "\n",
    "# Define the necessary global variables if not already defined\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "train_dir = 'Dataset/pest/train'\n",
    "test_dir = 'Dataset/pest/test' \n",
    "\n",
    "# Image dimensions\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Common data loading for TensorFlow models\n",
    "def load_tf_data(shuffle=True):\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        zca_epsilon=1e-06,\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=20,\n",
    "        zoom_range=0.8,\n",
    "        fill_mode=\"nearest\",\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        validation_split=0.1,\n",
    "        rescale=1./255\n",
    "    )\n",
    "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "    training = train_datagen.flow_from_directory(\n",
    "        train_dir, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        target_size=IMG_SIZE, \n",
    "        subset=\"training\",\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    validing = train_datagen.flow_from_directory(\n",
    "        train_dir, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        target_size=IMG_SIZE, \n",
    "        subset='validation', \n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    testing = test_datagen.flow_from_directory(\n",
    "        test_dir, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        target_size=IMG_SIZE, \n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    num_classes = len(training.class_indices)\n",
    "    class_labels = list(training.class_indices.keys())\n",
    "    return training, validing, testing, num_classes, class_labels\n",
    "\n",
    "# Utility function to plot and save training history\n",
    "def plot_training_history(history, model_name):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'{model_name} - Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'{model_name} - Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{model_name}_training_history.png')\n",
    "    plt.close()\n",
    "\n",
    "# Utility function to evaluate and visualize predictions\n",
    "def visualize_prediction(model, img_path, class_labels, model_name, is_tf_model=True):\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"Warning: Test image path {img_path} not found. Skipping prediction.\")\n",
    "        return\n",
    "    # Load and display the test image\n",
    "    test_img = cv2.imread(img_path)\n",
    "    test_img = cv2.resize(test_img, IMG_SIZE)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Test Image\")\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'{model_name}_test_image.png')\n",
    "    plt.close()\n",
    "    if is_tf_model:\n",
    "        # For TensorFlow models\n",
    "        img_array = image.img_to_array(image.load_img(img_path, target_size=IMG_SIZE))\n",
    "        img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "        prediction = model.predict(img_array)\n",
    "        predicted_class = np.argmax(prediction[0])\n",
    "        predicted_label = class_labels[predicted_class]\n",
    "        # Plot prediction probabilities\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.bar(class_labels, prediction[0])\n",
    "        plt.xlabel(\"Class\")\n",
    "        plt.ylabel(\"Probability\")\n",
    "        plt.title(f\"{model_name} - Prediction: {predicted_label}\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{model_name}_prediction.png')\n",
    "        plt.close()\n",
    "        print(f\"{model_name} Predicted Class: {predicted_label}\")\n",
    "    else:\n",
    "        # For PyTorch models (handled differently by each model's predict function)\n",
    "        print(f\"{model_name} prediction visualization is handled by the model's own function\")\n",
    "\n",
    "# ----- MODEL 1: MobileNetV2 Transfer Learning -----\n",
    "def build_mobilenetv2_model(num_classes):\n",
    "    base_model = MobileNetV2(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    "    )\n",
    "    \n",
    "    # Freeze the base model layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_mobilenetv2(training, validing, testing, num_classes):\n",
    "    print(\"\\n----- Training MobileNetV2 Transfer Learning Model -----\")\n",
    "    model = build_mobilenetv2_model(num_classes)\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=100, restore_best_weights=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=250, verbose=1)\n",
    "    ]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        training,\n",
    "        validation_data=validing,\n",
    "        epochs=500,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Evaluate on test data\n",
    "    test_loss, test_acc = model.evaluate(testing, verbose=0)\n",
    "    print(f\"MobileNetV2 Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "    print(f\"Training time: {training_time:.2f} seconds\")\n",
    "    \n",
    "    # Save model and plot training history\n",
    "    model.save(\"mobilenetv2_model.h5\")\n",
    "    plot_training_history(history, \"MobileNetV2\")\n",
    "    \n",
    "    return model, test_acc, training_time\n",
    "\n",
    "# ----- MODEL 2: Siamese Network -----\n",
    "# Euclidean distance function\n",
    "def euclidean_distance(vectors):\n",
    "    x, y = vectors\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def build_siamese_base():\n",
    "    base_model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3)\n",
    "    ])\n",
    "    return base_model\n",
    "\n",
    "def build_siamese_model():\n",
    "    base_network = build_siamese_base()\n",
    "    \n",
    "    input_a = Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "    input_b = Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "    \n",
    "    processed_a = base_network(input_a)\n",
    "    processed_b = base_network(input_b)\n",
    "    \n",
    "    distance = Lambda(euclidean_distance)([processed_a, processed_b])\n",
    "    output = Dense(1, activation='sigmoid')(distance)\n",
    "    \n",
    "    siamese_model = Model(inputs=[input_a, input_b], outputs=output)\n",
    "    siamese_model.compile(optimizer=Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return siamese_model\n",
    "\n",
    "def create_pairs(images_by_class, num_pairs_per_class=100):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    \n",
    "    # Same class pairs (label=1)\n",
    "    for class_images in images_by_class.values():\n",
    "        if len(class_images) < 2:\n",
    "            continue\n",
    "            \n",
    "        for _ in range(num_pairs_per_class):\n",
    "            # Randomly select two images from the same class\n",
    "            idx1, idx2 = random.sample(range(len(class_images)), 2)\n",
    "            pairs.append([class_images[idx1], class_images[idx2]])\n",
    "            labels.append(1)  # 1 indicates same class\n",
    "    \n",
    "    # Different class pairs (label=0)\n",
    "    classes = list(images_by_class.keys())\n",
    "    for _ in range(num_pairs_per_class * len(classes)):\n",
    "        # Select two different classes\n",
    "        class1, class2 = random.sample(classes, 2)\n",
    "        \n",
    "        # Select random images from these classes\n",
    "        img1 = random.choice(images_by_class[class1])\n",
    "        img2 = random.choice(images_by_class[class2])\n",
    "        \n",
    "        pairs.append([img1, img2])\n",
    "        labels.append(0)  # 0 indicates different classes\n",
    "    \n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "def load_images_from_directory(directory):\n",
    "    images_by_class = {}\n",
    "    class_indices = {}\n",
    "    \n",
    "    # Get all subdirectories (classes)\n",
    "    classes = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n",
    "    \n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_indices[class_name] = i\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        images_by_class[class_name] = []\n",
    "        \n",
    "        # Get all image files (limit to 50 per class to manage memory)\n",
    "        image_files = [f for f in os.listdir(class_dir) if f.endswith(('.jpg', '.jpeg', '.png'))][:50]\n",
    "        \n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(class_dir, img_file)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "                \n",
    "            img = cv2.resize(img, IMG_SIZE)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = img / 255.0  # Normalize to [0, 1]\n",
    "            images_by_class[class_name].append(img)\n",
    "            \n",
    "    return images_by_class, class_indices\n",
    "\n",
    "def prepare_pairs_for_model(pairs):\n",
    "    left_input = []\n",
    "    right_input = []\n",
    "    \n",
    "    for pair in pairs:\n",
    "        left_input.append(pair[0])\n",
    "        right_input.append(pair[1])\n",
    "        \n",
    "    return [np.array(left_input), np.array(right_input)]\n",
    "\n",
    "def classify_with_siamese(siamese_model, reference_images_by_class, test_image, threshold=0.5):\n",
    "    results = {}\n",
    "    \n",
    "    # For each class, compare the test image with all reference images\n",
    "    for class_name, ref_images in reference_images_by_class.items():\n",
    "        similarities = []\n",
    "        \n",
    "        for ref_img in ref_images:\n",
    "            # Prepare the pair\n",
    "            pair = prepare_pairs_for_model([[test_image, ref_img]])\n",
    "            \n",
    "            # Get similarity prediction (1 = same class, 0 = different class)\n",
    "            similarity = siamese_model.predict(pair, verbose=0)[0][0]\n",
    "            similarities.append(similarity)\n",
    "        \n",
    "        # Average similarity for this class\n",
    "        avg_similarity = np.mean(similarities)\n",
    "        results[class_name] = avg_similarity\n",
    "    \n",
    "    # Find the class with highest similarity\n",
    "    predicted_class = max(results, key=results.get)\n",
    "    confidence = results[predicted_class]\n",
    "    \n",
    "    # Only classify if confidence is above threshold\n",
    "    if confidence > threshold:\n",
    "        return predicted_class, results\n",
    "    else:\n",
    "        return \"Unknown\", results\n",
    "\n",
    "def train_siamese_network():\n",
    "    print(\"\\n----- Training Siamese Network Model -----\")\n",
    "    # Load images for training\n",
    "    train_images_by_class, class_indices = load_images_from_directory(train_dir)\n",
    "    print(f\"Found {len(class_indices)} classes\")\n",
    "    # Create pairs for training\n",
    "    print(\"Creating image pairs for training...\")\n",
    "    pairs, labels = create_pairs(train_images_by_class)\n",
    "    # Split into train and validation\n",
    "    train_pairs, val_pairs, train_labels, val_labels = train_test_split(\n",
    "        pairs, labels, test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "    # Prepare data for model\n",
    "    train_pair_data = prepare_pairs_for_model(train_pairs)\n",
    "    val_pair_data = prepare_pairs_for_model(val_pairs)\n",
    "    # Build and train model\n",
    "    siamese_model = build_siamese_model()\n",
    "    # Define callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=250, min_lr=1e-6, verbose=1)\n",
    "    # Train the model\n",
    "    start_time = time.time()\n",
    "    history = siamese_model.fit(\n",
    "        train_pair_data, train_labels,\n",
    "        validation_data=(val_pair_data, val_labels),\n",
    "        epochs=500,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    training_time = time.time() - start_time\n",
    "    # Save model\n",
    "    siamese_model.save(\"siamese_model.h5\")\n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Siamese Network - Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Siamese Network - Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('siamese_training_history.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Evaluate on test data\n",
    "    print(\"Loading test images for evaluation...\")\n",
    "    test_images_by_class, _ = load_images_from_directory(test_dir)\n",
    "    \n",
    "    # Create pairs for testing\n",
    "    print(\"Creating image pairs for testing...\")\n",
    "    test_pairs, test_labels = create_pairs(test_images_by_class, num_pairs_per_class=50)\n",
    "    test_pair_data = prepare_pairs_for_model(test_pairs)\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss, test_acc = siamese_model.evaluate(test_pair_data, test_labels, verbose=0)\n",
    "    print(f\"Siamese Network Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "    print(f\"Training time: {training_time:.2f} seconds\")\n",
    "    \n",
    "    # Test on a single image\n",
    "    img_test_path = 'Dataset/pest/test/beetle/jpg_33.jpg'\n",
    "    if os.path.exists(img_test_path):\n",
    "        # Load and preprocess the test image\n",
    "        img = cv2.imread(img_test_path)\n",
    "        img = cv2.resize(img, IMG_SIZE)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img / 255.0\n",
    "        \n",
    "        # Classify the test image\n",
    "        predicted_class, class_similarities = classify_with_siamese(\n",
    "            siamese_model, train_images_by_class, img\n",
    "        )\n",
    "        \n",
    "        print(f\"Siamese Network Predicted Class: {predicted_class}\")\n",
    "        \n",
    "        # Plot class similarities\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        classes = list(class_similarities.keys())\n",
    "        similarities = list(class_similarities.values())\n",
    "        \n",
    "        plt.bar(classes, similarities)\n",
    "        plt.xlabel(\"Class\")\n",
    "        plt.ylabel(\"Similarity Score\")\n",
    "        plt.title(\"Siamese Network - Class Similarity Scores\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('siamese_class_similarities.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return siamese_model, test_acc, training_time\n",
    "\n",
    "# ----- MODEL 3: GNN Model -----\n",
    "# Only run if PyTorch and PyTorch Geometric are available\n",
    "def train_gnn_model():\n",
    "    try:\n",
    "        print(\"\\n----- Training Graph Neural Network Model -----\")\n",
    "        # Function to convert an image into a graph\n",
    "        def image_to_graph(img_path, label):\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                return None\n",
    "            \n",
    "            img = cv2.resize(img, IMG_SIZE)\n",
    "            img = img_as_float(img)\n",
    "            \n",
    "            try:\n",
    "                segments = slic(img, n_segments=100, compactness=10)\n",
    "                \n",
    "                nodes = np.unique(segments)\n",
    "                features = []\n",
    "                \n",
    "                for node in nodes:\n",
    "                    mask = segments == node\n",
    "                    if np.sum(mask) > 0:\n",
    "                        mean_color = np.mean(img[mask], axis=0)\n",
    "                        std_color = np.std(img[mask], axis=0)\n",
    "                        features.append(np.concatenate([mean_color, std_color]))\n",
    "                \n",
    "                features = np.array(features)\n",
    "                \n",
    "                # Create spatial edge connections\n",
    "                edges = []\n",
    "                for i in range(len(nodes)):\n",
    "                    for j in range(i + 1, len(nodes)):\n",
    "                        if are_segments_adjacent(segments, nodes[i], nodes[j]):\n",
    "                            edges.append([i, j])\n",
    "                            edges.append([j, i])\n",
    "                \n",
    "                if len(edges) == 0:  # Fallback if no adjacency detected\n",
    "                    for i in range(len(nodes)):\n",
    "                        for j in range(i + 1, min(i + 5, len(nodes))):\n",
    "                            edges.append([i, j])\n",
    "                            edges.append([j, i])\n",
    "                \n",
    "                edges = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "                features = torch.tensor(features, dtype=torch.float)\n",
    "                \n",
    "                # Create a single label for the whole graph\n",
    "                y = torch.tensor(label, dtype=torch.long)\n",
    "                \n",
    "                return Data(x=features, edge_index=edges, y=y)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image: {e}\")\n",
    "                return None\n",
    "\n",
    "        # Check if two segments are adjacent\n",
    "        def are_segments_adjacent(segments, seg1, seg2):\n",
    "            mask1 = segments == seg1\n",
    "            mask2 = segments == seg2\n",
    "            \n",
    "            kernel = np.ones((3, 3), np.uint8)\n",
    "            dilated_mask1 = cv2.dilate(mask1.astype(np.uint8), kernel, iterations=1)\n",
    "            \n",
    "            return np.any(dilated_mask1 & mask2)\n",
    "\n",
    "        # GNN Model\n",
    "        class GNNModel(nn.Module):\n",
    "            def __init__(self, input_dim, hidden_dim, output_dim, dropout_rate=0.3):\n",
    "                super(GNNModel, self).__init__()\n",
    "                self.conv1 = GATConv(input_dim, hidden_dim)\n",
    "                self.conv2 = GATConv(hidden_dim, hidden_dim)\n",
    "                self.batch_norm1 = nn.BatchNorm1d(hidden_dim)\n",
    "                self.batch_norm2 = nn.BatchNorm1d(hidden_dim)\n",
    "                self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "                self.relu = nn.ReLU()\n",
    "                self.dropout = nn.Dropout(dropout_rate)\n",
    "            \n",
    "            def forward(self, data):\n",
    "                x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "                \n",
    "                if batch is None:\n",
    "                    batch = torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "                \n",
    "                x = self.conv1(x, edge_index)\n",
    "                x = self.batch_norm1(x)\n",
    "                x = self.relu(x)\n",
    "                x = self.dropout(x)\n",
    "                \n",
    "                x = self.conv2(x, edge_index)\n",
    "                x = self.batch_norm2(x)\n",
    "                x = self.relu(x)\n",
    "                x = self.dropout(x)\n",
    "                \n",
    "                x = global_mean_pool(x, batch)\n",
    "                x = self.fc(x)\n",
    "                \n",
    "                return x\n",
    "\n",
    "        # Function to create dataset from directory\n",
    "        def create_dataset(root_dir, class_indices):\n",
    "            dataset = []\n",
    "            class_counts = {}\n",
    "            \n",
    "            for class_name, idx in class_indices.items():\n",
    "                class_dir = os.path.join(root_dir, class_name)\n",
    "                if not os.path.isdir(class_dir):\n",
    "                    continue\n",
    "                    \n",
    "                image_files = [f for f in os.listdir(class_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "                \n",
    "                max_images = 50\n",
    "                selected_files = image_files[:min(max_images, len(image_files))]\n",
    "                class_counts[class_name] = len(selected_files)\n",
    "                \n",
    "                for img_file in selected_files:\n",
    "                    img_path = os.path.join(class_dir, img_file)\n",
    "                    graph_data = image_to_graph(img_path, idx)\n",
    "                    if graph_data is not None:\n",
    "                        dataset.append(graph_data)\n",
    "            \n",
    "            print(f\"Dataset creation summary: {class_counts}\")\n",
    "            return dataset\n",
    "\n",
    "        # Get class indices from TensorFlow's ImageDataGenerator for consistency\n",
    "        datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "        temp_gen = datagen.flow_from_directory(\n",
    "            train_dir, \n",
    "            batch_size=1,\n",
    "            target_size=IMG_SIZE,\n",
    "            shuffle=True\n",
    "        )\n",
    "        class_indices = temp_gen.class_indices\n",
    "        num_classes = len(class_indices)\n",
    "        \n",
    "        # Create datasets\n",
    "        print(\"Creating training dataset...\")\n",
    "        train_dataset = create_dataset(train_dir, class_indices)\n",
    "        print(\"Creating testing dataset...\")\n",
    "        test_dataset = create_dataset(test_dir, class_indices)\n",
    "        \n",
    "        if not train_dataset:\n",
    "            raise ValueError(\"No training data could be created.\")\n",
    "        \n",
    "        # Split training data into train and validation\n",
    "        train_data, val_data = train_test_split(train_dataset, test_size=0.2, random_state=42, shuffle=True)\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "        val_loader = DataLoader(val_data, batch_size=8, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n",
    "        \n",
    "        # Get feature dimension from data\n",
    "        input_dim = train_data[0].x.shape[1] if train_data else 6\n",
    "        \n",
    "        # Create and train model\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {device}\")\n",
    "        model = GNNModel(input_dim=input_dim, hidden_dim=64, output_dim=num_classes).to(device)\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "        \n",
    "        # Training loop with early stopping\n",
    "        best_val_loss = float('inf')\n",
    "        patience = 100\n",
    "        counter = 0\n",
    "        early_stop = False\n",
    "        epochs = 500\n",
    "        \n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        train_accs = []\n",
    "        val_accs = []\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            if early_stop:\n",
    "                print(\"Early stopping triggered!\")\n",
    "                break\n",
    "                \n",
    "            # Training\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for batch in train_loader:\n",
    "                batch = batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                try:\n",
    "                    output = model(batch)\n",
    "                    loss = criterion(output, batch.y)\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    \n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    total_loss += loss.item()\n",
    "                    _, predicted = output.max(dim=1)\n",
    "                    total += batch.y.size(0)\n",
    "                    correct += predicted.eq(batch.y).sum().item()\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "            \n",
    "            if total > 0:\n",
    "                train_loss = total_loss / len(train_loader)\n",
    "                train_acc = 100.0 * correct / total\n",
    "                train_losses.append(train_loss)\n",
    "                train_accs.append(train_acc)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    batch = batch.to(device)\n",
    "                    try:\n",
    "                        output = model(batch)\n",
    "                        loss = criterion(output, batch.y)\n",
    "                        \n",
    "                        val_loss += loss.item()\n",
    "                        _, predicted = output.max(dim=1)\n",
    "                        total += batch.y.size(0)\n",
    "                        correct += predicted.eq(batch.y).sum().item()\n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "            \n",
    "            if total > 0:\n",
    "                val_loss = val_loss / len(val_loader)\n",
    "                val_acc = 100.0 * correct / total\n",
    "                val_losses.append(val_loss)\n",
    "                val_accs.append(val_acc)\n",
    "                \n",
    "                scheduler.step(val_loss)\n",
    "                \n",
    "                print(f\"Epoch {epoch+1}/{epochs}, \"\n",
    "                      f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
    "                      f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "                \n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    counter = 0\n",
    "                    torch.save(model.state_dict(), \"best_gnn_model.pth\")\n",
    "                else:\n",
    "                    counter += 1\n",
    "                    if counter >= patience:\n",
    "                        early_stop = True\n",
    "            else:\n",
    "                print(\"Warning: No valid batches in validation epoch\")\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # Plot training curves\n",
    "        if train_losses and val_losses:\n",
    "            plt.figure(figsize=(12, 5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(train_losses, label='Train Loss')\n",
    "            plt.plot(val_losses, label='Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(train_accs, label='Train Accuracy')\n",
    "            plt.plot(val_accs, label='Validation Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy (%)')\n",
    "            plt.legend()\n",
    "            plt.savefig('gnn_training_curves.png')\n",
    "            plt.close()\n",
    "        \n",
    "        # Evaluate best model on test set\n",
    "        model.load_state_dict(torch.load(\"best_gnn_model.pth\"))\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        idx_to_class = {v: k for k, v in class_indices.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                batch = batch.to(device)\n",
    "                try:\n",
    "                    output = model(batch)\n",
    "                    _, predicted = output.max(dim=1)\n",
    "                    \n",
    "                    total += batch.y.size(0)\n",
    "                    correct += predicted.eq(batch.y).sum().item()\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "        \n",
    "        if total > 0:\n",
    "            test_acc = 100.0 * correct / total\n",
    "            print(f\"GNN Test Accuracy: {test_acc:.2f}%\")\n",
    "        else:\n",
    "            test_acc = 0\n",
    "            print(\"Warning: No valid batches in test evaluation\")\n",
    "            \n",
    "        print(f\"Training time: {training_time:.2f} seconds\")\n",
    "        \n",
    "        return model, test_acc, training_time\n",
    "    except Exception as e:\n",
    "        print(f\"Could not train GNN model: {e}\")\n",
    "        return None, 0, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c46029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchExtractor(tf.keras.layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(PatchExtractor, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "    \n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\"\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "\n",
    "# ----- MODEL 4: Vision Transformer -----\n",
    "def build_vit_model(num_classes, image_size=224, patch_size=16, num_heads=8, \n",
    "                   transformer_layers=8, hidden_units=64, mlp_units=128):  \n",
    "    input_shape = (image_size, image_size, 3)\n",
    "    num_patches = (image_size // patch_size) ** 2\n",
    "    projection_dim = hidden_units\n",
    "    # Input layer\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape) \n",
    "    # Create patches and project them\n",
    "    patches = PatchExtractor(patch_size)(inputs)\n",
    "    patch_projection = tf.keras.layers.Dense(projection_dim)(patches)\n",
    "    # Add positional embeddings\n",
    "    positions = tf.range(start=0, limit=num_patches, delta=1)\n",
    "    position_embedding = tf.keras.layers.Embedding(\n",
    "        input_dim=num_patches, output_dim=projection_dim\n",
    "    )(positions)\n",
    "    encoded_patches = patch_projection + position_embedding\n",
    "    # Create transformer blocks\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1\n",
    "        x1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Multi-head attention\n",
    "        attention_output = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim // num_heads, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        \n",
    "        # Skip connection 1\n",
    "        x2 = tf.keras.layers.Add()([attention_output, encoded_patches])\n",
    "        \n",
    "        # Layer normalization 2\n",
    "        x3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        \n",
    "        # MLP\n",
    "        x4 = tf.keras.layers.Dense(mlp_units, activation=\"gelu\")(x3)\n",
    "        x4 = tf.keras.layers.Dropout(0.1)(x4)\n",
    "        x4 = tf.keras.layers.Dense(projection_dim)(x4)\n",
    "        x4 = tf.keras.layers.Dropout(0.1)(x4)\n",
    "        \n",
    "        # Skip connection 2\n",
    "        encoded_patches = tf.keras.layers.Add()([x4, x2])\n",
    "\n",
    "    # Final layer normalization and global pooling\n",
    "    representation = tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = tf.keras.layers.GlobalAveragePooling1D()(representation)\n",
    "    # Classification head\n",
    "    representation = tf.keras.layers.Dropout(0.3)(representation)\n",
    "    features = tf.keras.layers.Dense(256, activation=\"relu\")(representation)\n",
    "    features = tf.keras.layers.BatchNormalization()(features)\n",
    "    features = tf.keras.layers.Dropout(0.3)(features)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(features)\n",
    "    # Create the model\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_vit_model(training, validing, testing, num_classes):\n",
    "    print(\"\\n----- Training Vision Transformer Model -----\")\n",
    "    model = build_vit_model(\n",
    "        num_classes=num_classes,\n",
    "        image_size=IMG_SIZE[0],\n",
    "        patch_size=16,\n",
    "        num_heads=8,\n",
    "        transformer_layers=6,\n",
    "        hidden_units=64,\n",
    "        mlp_units=128\n",
    "    )\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
    "    ]\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        training,\n",
    "        validation_data=validing,\n",
    "        epochs=500,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    training_time = time.time() - start_time\n",
    "    # Evaluate on test data\n",
    "    test_loss, test_acc = model.evaluate(testing, verbose=0)\n",
    "    print(f\"Vision Transformer Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "    print(f\"Training time: {training_time:.2f} seconds\")\n",
    "    # Save model and plot training history\n",
    "    model.save(\"vit_model.h5\")\n",
    "    plot_training_history(history, \"VisionTransformer\")\n",
    "    return model, test_acc, training_time\n",
    "\n",
    "# Main function to run all models and compare results\n",
    "def main():\n",
    "    # Load data\n",
    "    training, validing, testing, num_classes, class_labels = load_tf_data()\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    print(f\"Class labels: {class_labels}\")\n",
    "    # Dictionary to store results\n",
    "    results = {}\n",
    "    # Train MobileNetV2 model\n",
    "    mobilenetv2_model, mobilenetv2_acc, mobilenetv2_time = train_mobilenetv2(training, validing, testing, num_classes)\n",
    "    results[\"MobileNetV2\"] = {\"accuracy\": mobilenetv2_acc, \"training_time\": mobilenetv2_time}\n",
    "    # Visualize prediction for a sample image\n",
    "    sample_img = 'Dataset/pest/test/beetle/jpg_33.jpg'\n",
    "    if os.path.exists(sample_img):\n",
    "        visualize_prediction(mobilenetv2_model, sample_img, class_labels, \"MobileNetV2\")\n",
    "    # Train Siamese Network\n",
    "    siamese_model, siamese_acc, siamese_time = train_siamese_network()\n",
    "    results[\"Siamese\"] = {\"accuracy\": siamese_acc, \"training_time\": siamese_time}\n",
    "    # Train GNN model if possible\n",
    "    try:\n",
    "        gnn_model, gnn_acc, gnn_time = train_gnn_model()\n",
    "        if gnn_model is not None:\n",
    "            results[\"GNN\"] = {\"accuracy\": gnn_acc, \"training_time\": gnn_time}\n",
    "    except Exception as e:\n",
    "        print(f\"Could not train GNN model: {e}\")\n",
    "    \n",
    "    # Train Vision Transformer model\n",
    "    vit_model, vit_acc, vit_time = train_vit_model(training, validing, testing, num_classes)\n",
    "    results[\"VisionTransformer\"] = {\"accuracy\": vit_acc, \"training_time\": vit_time}\n",
    "    \n",
    "    if os.path.exists(sample_img):\n",
    "        visualize_prediction(vit_model, sample_img, class_labels, \"VisionTransformer\")\n",
    "    \n",
    "    # Compare model performances\n",
    "    print(\"\\n----- Model Performance Comparison -----\")\n",
    "    for model_name, metrics in results.items():\n",
    "        print(f\"{model_name}: Accuracy = {metrics['accuracy'] * 100:.2f}%, Training Time = {metrics['training_time']:.2f} seconds\")\n",
    "    # Plot comparison chart\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Accuracy comparison\n",
    "    plt.subplot(1, 2, 1)\n",
    "    model_names = list(results.keys())\n",
    "    accuracies = [results[model][\"accuracy\"] * 100 for model in model_names]\n",
    "    plt.bar(model_names, accuracies, color='skyblue')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Model Accuracy Comparison')\n",
    "    plt.ylim([0, 100])\n",
    "    \n",
    "    # Training time comparison\n",
    "    plt.subplot(1, 2, 2)\n",
    "    training_times = [results[model][\"training_time\"] for model in model_names]\n",
    "    plt.bar(model_names, training_times, color='salmon')\n",
    "    plt.ylabel('Training Time (seconds)')\n",
    "    plt.title('Model Training Time Comparison')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Comparison chart saved as 'model_comparison.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f61cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
